{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf14a0f8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <br><font face = \"Times New Roman\" size = \"6\"><b><center>PROYECTO FINAL</center></b></font>\n",
    "    <br><font face = \"Times New Roman\" size = \"5\"><b><center>Asignatura: Ing. de Características - Maestría en Informática Aplicada</center></b></font>\n",
    "    <br><font face = \"Times New Roman\" size = \"4\"><center>Profesor: Mtro. Gaddiel Desirena López</center></font>\n",
    "    <font face = \"Times New Roman\" size = \"4\"><center>Alumnos:</center></font>\n",
    "    <font face = \"Times New Roman\" size = \"4\"><center>Vanessa Suárez Blanco</center></font>\n",
    "    <font face = \"Times New Roman\" size = \"4\"><center>Pedro Ibarra González</center></font>\n",
    "        <font face = \"Times New Roman\" size = \"4\"><center>09 de Mayo de 2024</center></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90adc6c0",
   "metadata": {},
   "source": [
    "Actualmente, con los avances en las tecnologías de la información, la generación de datos de diversos tipos en un solo día tiene volúmenes muy altos y con tendencia creciente. Con el fin del aprovechamiento de la información valiosa que pueda estar oculta en los datos que se generan, se requieren tener conocimientos básicos de manejo de información, ingeniería de características y de análisis exploratorio de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a63708",
   "metadata": {},
   "source": [
    "De forma general, a menos que la persona sea una experta en el fenómeno en el cual se están generando los datos, el ingeniero que se disponga al análisis de los datos generados debe de realizar un análisis exploratorio para rescatar las características básicas que poseen los datos\n",
    "\n",
    "\n",
    "El objetivo del proyecto final es realizar un Análisis Exploratorio de Datos (EDA) a la base de datos asignada o elegida por el equipo y realizar las siguientes actividades:\n",
    "\n",
    "\n",
    "1.- Aplicar las técnicas y algoritmos vistos en los tres parciales del curso:\n",
    "\n",
    "-  Identificación de datos\n",
    "-  Tratamiento de datos faltantes \n",
    "-  Codificación de variables categóricas \n",
    "-  Transformación de variables numéricas\n",
    "-  Escalamiento de variables \n",
    "-  Discretización de variables\n",
    "\n",
    "\n",
    "2.- Del dataframe obtenido realizar una clusterización mediante los algoritmos \n",
    "-  Kmeans++\n",
    "-  Arboles de decisión\n",
    "-  Clustering jerárquico. \n",
    "\n",
    "Obtenga gráficas y comentarios de sus resultados.\n",
    "\n",
    "\n",
    "3.- Finalmente, del conjunto de datos, identificar la o las variables de salida y las variables de entrada para entrenar algún algoritmo de ML (Arboles de desición, Regresiones lineales, etc… ), se requiere obtener un accuracy arriba del 80%, si el accuracy está por debajo de este valor, entonces será necesario repetir el punto 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acb0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borrar después\n",
    "#Entregables:\n",
    "\n",
    "#• Presentación con diapositivas\n",
    "\n",
    "#• Reporte que valide la realización del proyecto.\n",
    "\n",
    "#• Código en Jupyter notebook del proceso del proyecto, analíticas, comentarios y gráficas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5122c3c1",
   "metadata": {},
   "source": [
    "El conjunto de datos de LinkedIn proporcionado contiene **7,927 filas y 15 columnas**, ofreciendo una visión general completa de las ofertas de empleo en la plataforma. \n",
    "\n",
    "Los datos se pueden utilizar para análisis de datos, visualización e investigación. Las ofertas de empleo incluyen roles de Analista de Datos, Ingeniero de Aprendizaje Automático, Servicios de TI y Consultoría de TI, ubicados en diversos lugares del mundo, con salarios y horarios de trabajo variados. \n",
    "\n",
    "El conjunto de datos incluye información sobre la empresa, las responsabilidades del rol y las habilidades requeridas para cada empleo. Este conjunto de datos es un recurso valioso para comprender las oportunidades laborales en diferentes industrias y ubicaciones.\n",
    "\n",
    "Descripciones de las columnas:\n",
    "- **job_ID**: Identificador único para cada oferta de empleo.\n",
    "- **job**: El título de la oferta de empleo.\n",
    "- **location**: La ubicación de la oferta de empleo.\n",
    "- **company_id**: El identificador único de la empresa que ofrece el empleo.\n",
    "- **company_name**: El nombre de la empresa que ofrece el empleo.\n",
    "- **work_type**: El tipo de trabajo ofrecido (por ejemplo, tiempo completo, tiempo parcial, etc.).\n",
    "- **full_time_remote**: Indica si el empleo es una posición remota a tiempo completo.\n",
    "- **no_of_employ**: El número de empleados en la empresa que ofrece el empleo.\n",
    "- **no_of_application**: El número de solicitudes recibidas para el empleo.\n",
    "- **posted_day_ago**: El número de días desde que se publicó el empleo.\n",
    "- **alumni**: Indica si la oferta de empleo es para exalumnos de una determinada organización.\n",
    "- **Hiring_person**: El nombre de la persona responsable de contratar para el empleo.\n",
    "- **linkedin_followers**: El número de seguidores en LinkedIn de la persona que contrata.\n",
    "- **hiring_person_link**: Un enlace al perfil de LinkedIn de la persona que contrata.\n",
    "- **job_details**: Información detallada sobre el empleo, incluyendo responsabilidades y requisitos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83f5d7",
   "metadata": {},
   "source": [
    "### 1.- Aplicar las técnicas y algoritmos vistos en los tres parciales del curso:\n",
    "\n",
    "#### Conocimiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5d5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Librerias de toda la tarea\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4354de91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_ID</th>\n",
       "      <th>job</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>work_type</th>\n",
       "      <th>full_time_remote</th>\n",
       "      <th>no_of_employ</th>\n",
       "      <th>no_of_application</th>\n",
       "      <th>posted_day_ago</th>\n",
       "      <th>alumni</th>\n",
       "      <th>Hiring_person</th>\n",
       "      <th>linkedin_followers</th>\n",
       "      <th>hiring_person_link</th>\n",
       "      <th>job_details</th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3471657636</td>\n",
       "      <td>Data Analyst, Trilogy (Remote) - $60,000/year USD</td>\n",
       "      <td>Delhi, Delhi, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crossover</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>200</td>\n",
       "      <td>8 hours</td>\n",
       "      <td>12 company alumni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,395,547 followers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job Crossover is the world's #1 sour...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3471669068</td>\n",
       "      <td>Data Analyst, Trilogy (Remote) - $60,000/year USD</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crossover</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>184</td>\n",
       "      <td>8 hours</td>\n",
       "      <td>12 company alumni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,395,547 followers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job Crossover is the world's #1 sour...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3474349934</td>\n",
       "      <td>Data Analyst - WFH</td>\n",
       "      <td>Greater Bengaluru Area</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uplers</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>200</td>\n",
       "      <td>9 hours</td>\n",
       "      <td>3 company alumni</td>\n",
       "      <td>Shahid Ahmad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/in/shahid-ahmad-a2613...</td>\n",
       "      <td>About the job Profile: ML EngineersExperience:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3472816027</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PVAR SERVICES</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1-10 employees</td>\n",
       "      <td>200</td>\n",
       "      <td>7 hours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vartika Singh</td>\n",
       "      <td>2,094 followers</td>\n",
       "      <td>https://www.linkedin.com/in/vartika-singh-</td>\n",
       "      <td>About the job Designation: Data AnalystLocatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3473311511</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mohali district, Punjab, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Timeline Freight Brokers</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1-10 employees</td>\n",
       "      <td>8</td>\n",
       "      <td>26 minutes</td>\n",
       "      <td>1 company alumni</td>\n",
       "      <td>Manisha (Gisele Smith)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/in/manisharathore0029</td>\n",
       "      <td>About the job The ideal candidate will use the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_ID                                                job  \\\n",
       "0  3471657636  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
       "1  3471669068  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
       "2  3474349934                                 Data Analyst - WFH   \n",
       "3  3472816027                                       Data Analyst   \n",
       "4  3473311511                                       Data Analyst   \n",
       "\n",
       "                         location  company_id              company_name  \\\n",
       "0             Delhi, Delhi, India         NaN                 Crossover   \n",
       "1         New Delhi, Delhi, India         NaN                 Crossover   \n",
       "2          Greater Bengaluru Area         NaN                    Uplers   \n",
       "3        Gurugram, Haryana, India         NaN             PVAR SERVICES   \n",
       "4  Mohali district, Punjab, India         NaN  Timeline Freight Brokers   \n",
       "\n",
       "  work_type              full_time_remote  \\\n",
       "0    Remote         Full-time · Associate   \n",
       "1    Remote         Full-time · Associate   \n",
       "2    Remote  Full-time · Mid-Senior level   \n",
       "3   On-site                     Full-time   \n",
       "4   On-site                     Full-time   \n",
       "\n",
       "                                        no_of_employ no_of_application  \\\n",
       "0  1,001-5,000 employees · IT Services and IT Con...               200   \n",
       "1  1,001-5,000 employees · IT Services and IT Con...               184   \n",
       "2  1,001-5,000 employees · IT Services and IT Con...               200   \n",
       "3                                     1-10 employees               200   \n",
       "4                                     1-10 employees                 8   \n",
       "\n",
       "  posted_day_ago             alumni           Hiring_person  \\\n",
       "0        8 hours  12 company alumni                     NaN   \n",
       "1        8 hours  12 company alumni                     NaN   \n",
       "2        9 hours   3 company alumni            Shahid Ahmad   \n",
       "3        7 hours                NaN           Vartika Singh   \n",
       "4     26 minutes   1 company alumni  Manisha (Gisele Smith)   \n",
       "\n",
       "    linkedin_followers                                 hiring_person_link  \\\n",
       "0  5,395,547 followers                                                NaN   \n",
       "1  5,395,547 followers                                                NaN   \n",
       "2                  NaN  https://www.linkedin.com/in/shahid-ahmad-a2613...   \n",
       "3      2,094 followers         https://www.linkedin.com/in/vartika-singh-   \n",
       "4                  NaN     https://www.linkedin.com/in/manisharathore0029   \n",
       "\n",
       "                                         job_details  Column1  \n",
       "0  About the job Crossover is the world's #1 sour...      NaN  \n",
       "1  About the job Crossover is the world's #1 sour...      NaN  \n",
       "2  About the job Profile: ML EngineersExperience:...      NaN  \n",
       "3  About the job Designation: Data AnalystLocatio...      NaN  \n",
       "4  About the job The ideal candidate will use the...      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos el df de LinkedIn desde un archivo CSV\n",
    "df = pd.read_csv('./linkedin.csv')\n",
    "\n",
    "# Mostramos las pirmeras linas para familiarizarnos los datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a7c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7927 entries, 0 to 7926\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   job_ID              7927 non-null   int64  \n",
      " 1   job                 7894 non-null   object \n",
      " 2   location            7894 non-null   object \n",
      " 3   company_id          0 non-null      float64\n",
      " 4   company_name        7892 non-null   object \n",
      " 5   work_type           7736 non-null   object \n",
      " 6   full_time_remote    7848 non-null   object \n",
      " 7   no_of_employ        7603 non-null   object \n",
      " 8   no_of_application   7887 non-null   object \n",
      " 9   posted_day_ago      7920 non-null   object \n",
      " 10  alumni              4858 non-null   object \n",
      " 11  Hiring_person       5720 non-null   object \n",
      " 12  linkedin_followers  4814 non-null   object \n",
      " 13  hiring_person_link  5720 non-null   object \n",
      " 14  job_details         7881 non-null   object \n",
      " 15  Column1             0 non-null      float64\n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 991.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "#Por los resultados percibimos que hay valores nulos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100e0276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_ID                5843\n",
      "job                   2991\n",
      "location               151\n",
      "company_id               0\n",
      "company_name          2495\n",
      "work_type                3\n",
      "full_time_remote        23\n",
      "no_of_employ           269\n",
      "no_of_application      202\n",
      "posted_day_ago          91\n",
      "alumni                 191\n",
      "Hiring_person         2823\n",
      "linkedin_followers    3935\n",
      "hiring_person_link    2845\n",
      "job_details           4563\n",
      "Column1                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "valores_unicos = df.nunique()\n",
    "\n",
    "# Mostrar el número de valores únicos para cada columna\n",
    "print(valores_unicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ee2521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_ID</th>\n",
       "      <th>company_id</th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.927000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.466724e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.778011e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.419216e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.467367e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.471882e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.476181e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.477823e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_ID  company_id  Column1\n",
       "count  7.927000e+03         0.0      0.0\n",
       "mean   3.466724e+09         NaN      NaN\n",
       "std    5.778011e+07         NaN      NaN\n",
       "min    1.419216e+08         NaN      NaN\n",
       "25%    3.467367e+09         NaN      NaN\n",
       "50%    3.471882e+09         NaN      NaN\n",
       "75%    3.476181e+09         NaN      NaN\n",
       "max    3.477823e+09         NaN      NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfa6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop de Column1 y Company_id ya que es una columna totalmente vacia, no tiene datos sólo el header\n",
    "df.drop('Column1', axis=1, inplace=True)\n",
    "df.drop('company_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ceb465",
   "metadata": {},
   "source": [
    "### Identificación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5571c5",
   "metadata": {},
   "source": [
    "#### Variables Binarias\n",
    "alumni_binary: Indica la presencia (1) o ausencia (0) de exalumnos, derivado de la columna alumni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9dc110",
   "metadata": {},
   "source": [
    "#### Variables Nominales\n",
    "-  job: El título de la oferta de empleo.\n",
    "-  location: Ubicación de la oferta de empleo.\n",
    "-  company_name: Nombre de la empresa que ofrece el empleo.\n",
    "-  work_type: Tipo de trabajo ofrecido (e.g., tiempo completo, tiempo parcial).\n",
    "-  full_time_remote: Indica si el empleo es a tiempo completo y remoto o no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966a7cd",
   "metadata": {},
   "source": [
    "#### Variables Ordinales\n",
    "-  full_time_remote: Podría considerarse ordinal si las categorías implican un orden de tipo de contrato o nivel de senioridad (e.g., Asociado vs. Nivel Senior)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a4fb9",
   "metadata": {},
   "source": [
    "#### Variables Numéricas\n",
    "-  job_ID: Identificador único para cada oferta de empleo.\n",
    "-  no_of_application_clean: Número de aplicaciones, extraído y convertido a formato numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dfab65e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Numéricas: ['job_ID', 'no_of_application_clean', 'alumni_binary']\n",
      "Variables Binarias: ['alumni_binary']\n",
      "Variables Nominales: ['job', 'location', 'company_name', 'work_type', 'full_time_remote']\n",
      "Variables Ordinales: ['full_time_remote']\n"
     ]
    }
   ],
   "source": [
    "# Extracción de números para 'no_of_application'\n",
    "df['no_of_application_clean'] = df['no_of_application'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Considerando 'alumni' como binaria, donde no NaN implica la presencia de alumni (1) y NaN la ausencia (0)\n",
    "df['alumni_binary'] = df['alumni'].notna().astype(int)\n",
    "\n",
    "# Identificación de variables numéricas, binarias, nominales y ordinales\n",
    "# Variables numéricas: Aquellas columnas que son float o int después de limpieza y conversión\n",
    "numeric_columns_df = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Variables binarias: Aquellas que tienen solo dos valores únicos y probablemente sean booleanas\n",
    "binary_columns_df = [col for col in df.columns if df[col].nunique() == 2]\n",
    "\n",
    "# Variables nominales y ordinales: Aquellas que contienen texto o categorías\n",
    "# Para simplificación, aquí se consideran nominales las columnas de texto sin un orden explícito y ordinales las que puedan tener un orden lógico\n",
    "nominal_columns_df = ['job', 'location', 'company_name', 'work_type', 'full_time_remote']\n",
    "ordinal_columns_df = ['full_time_remote']  # Este es un ejemplo, podría necesitar revisión\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Variables Numéricas:\", numeric_columns_df)\n",
    "print(\"Variables Binarias:\", binary_columns_df)\n",
    "print(\"Variables Nominales:\", nominal_columns_df)\n",
    "print(\"Variables Ordinales:\", ordinal_columns_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c76aa",
   "metadata": {},
   "source": [
    "#### Tratamiento de datos faltantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca63edbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: fuzzywuzzy in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (0.18.0)\n",
      "Requirement already satisfied: python-Levenshtein in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: Levenshtein==0.25.1 in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (from python-Levenshtein) (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (from Levenshtein==0.25.1->python-Levenshtein) (3.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vksuarez/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas fuzzywuzzy python-Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6804ba6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tu_archivo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfuzzywuzzy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Cargar el dataset\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtu_archivo.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Asegúrate de cambiar 'tu_archivo.csv' por el nombre de tu archivo\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Lista de categorías principales basada en títulos comunes de trabajo\u001b[39;00m\n\u001b[1;32m      8\u001b[0m categorias_principales \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Analyst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftware Engineer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject Manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct Manager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccount Manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSales Representative\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData Scientist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBusiness Analyst\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystems Analyst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsultant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuality Assurance Engineer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSEO Specialist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tu_archivo.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('tu_archivo.csv')  # Asegúrate de cambiar 'tu_archivo.csv' por el nombre de tu archivo\n",
    "\n",
    "# Lista de categorías principales basada en títulos comunes de trabajo\n",
    "categorias_principales = [\n",
    "    \"Data Analyst\", \"Software Engineer\", \"Project Manager\", \"Product Manager\",\n",
    "    \"Account Manager\", \"Sales Representative\", \"Data Scientist\", \"Business Analyst\",\n",
    "    \"Marketing Manager\", \"Graphic Designer\", \"UX/UI Designer\", \"Operations Manager\",\n",
    "    \"Financial Analyst\", \"Human Resources Manager\", \"Administrative Assistant\",\n",
    "    \"Customer Service Representative\", \"Web Developer\", \"Network Engineer\",\n",
    "    \"Systems Analyst\", \"Consultant\", \"Quality Assurance Engineer\", \"SEO Specialist\"\n",
    "]\n",
    "\n",
    "# Función para categorizar los trabajos\n",
    "def categorizar_posicion(posicion):\n",
    "    # Encuentra la coincidencia más cercana de la posición en la lista de categorías principales\n",
    "    categoria, score = process.extractOne(posicion, categorias_principales)\n",
    "    # Puedes ajustar el umbral de score según lo necesites para hacerlo más o menos estricto\n",
    "    if score > 85:\n",
    "        return categoria\n",
    "    else:\n",
    "        return \"Otro\"\n",
    "\n",
    "# Aplicar la función a la columna 'job'\n",
    "df['categoria'] = df['job'].apply(categorizar_posicion)\n",
    "\n",
    "# Guardar los resultados en un nuevo CSV\n",
    "df.to_csv('tu_archivo_categorizado.csv', index=False)\n",
    "\n",
    "# Imprimir las categorías únicas\n",
    "print(df['categoria'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ac7f8",
   "metadata": {},
   "source": [
    "#### Codificación de variables categóricas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512878d5",
   "metadata": {},
   "source": [
    "#### Transformación de variables numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8b3e7",
   "metadata": {},
   "source": [
    "#### Escalamiento de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e251e",
   "metadata": {},
   "source": [
    "#### Discretización de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7361e5e",
   "metadata": {},
   "source": [
    "### 2.- Del dataframe obtenido realizar una clusterización mediante los algoritmos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c9169",
   "metadata": {},
   "source": [
    "#### -  Kmeans++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5139ce",
   "metadata": {},
   "source": [
    "#### -  Arboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756448b3",
   "metadata": {},
   "source": [
    "#### -  Clustering jerárquico. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a9bec",
   "metadata": {},
   "source": [
    "#### Gráficas y análisis de resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf59ee5",
   "metadata": {},
   "source": [
    "### 3.- Finalmente, del conjunto de datos, identificar la o las variables de salida y las variables de entrada para entrenar algún algoritmo de ML (Arboles de desición, Regresiones lineales, etc… ), se requiere obtener un accuracy arriba del 80%, si el accuracy está por debajo de este valor, entonces será necesario repetir el punto 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b10761",
   "metadata": {},
   "source": [
    "#### Variable o variables de salida y de entrada que se usarán para entrenar al algoritmo de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ed99e",
   "metadata": {},
   "source": [
    "#### código con el modelo de árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e827de",
   "metadata": {},
   "source": [
    "#### código con el modelo de regresión lineal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea209509",
   "metadata": {},
   "source": [
    "#### Celda para calcular el score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b092aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881088fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('linkedin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7aaefd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_ID</th>\n",
       "      <th>job</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>work_type</th>\n",
       "      <th>full_time_remote</th>\n",
       "      <th>no_of_employ</th>\n",
       "      <th>no_of_application</th>\n",
       "      <th>posted_day_ago</th>\n",
       "      <th>alumni</th>\n",
       "      <th>Hiring_person</th>\n",
       "      <th>linkedin_followers</th>\n",
       "      <th>hiring_person_link</th>\n",
       "      <th>job_details</th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3471657636</td>\n",
       "      <td>Data Analyst, Trilogy (Remote) - $60,000/year USD</td>\n",
       "      <td>Delhi, Delhi, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crossover</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>200</td>\n",
       "      <td>8 hours</td>\n",
       "      <td>12 company alumni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,395,547 followers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job Crossover is the world's #1 sour...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3471669068</td>\n",
       "      <td>Data Analyst, Trilogy (Remote) - $60,000/year USD</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crossover</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>184</td>\n",
       "      <td>8 hours</td>\n",
       "      <td>12 company alumni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,395,547 followers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job Crossover is the world's #1 sour...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3474349934</td>\n",
       "      <td>Data Analyst - WFH</td>\n",
       "      <td>Greater Bengaluru Area</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uplers</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>200</td>\n",
       "      <td>9 hours</td>\n",
       "      <td>3 company alumni</td>\n",
       "      <td>Shahid Ahmad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/in/shahid-ahmad-a2613...</td>\n",
       "      <td>About the job Profile: ML EngineersExperience:...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3472816027</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PVAR SERVICES</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1-10 employees</td>\n",
       "      <td>200</td>\n",
       "      <td>7 hours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vartika Singh</td>\n",
       "      <td>2,094 followers</td>\n",
       "      <td>https://www.linkedin.com/in/vartika-singh-</td>\n",
       "      <td>About the job Designation: Data AnalystLocatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3473311511</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mohali district, Punjab, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Timeline Freight Brokers</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1-10 employees</td>\n",
       "      <td>8</td>\n",
       "      <td>26 minutes</td>\n",
       "      <td>1 company alumni</td>\n",
       "      <td>Manisha (Gisele Smith)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/in/manisharathore0029</td>\n",
       "      <td>About the job The ideal candidate will use the...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_ID                                                job  \\\n",
       "0  3471657636  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
       "1  3471669068  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
       "2  3474349934                                 Data Analyst - WFH   \n",
       "3  3472816027                                       Data Analyst   \n",
       "4  3473311511                                       Data Analyst   \n",
       "\n",
       "                         location  company_id              company_name  \\\n",
       "0             Delhi, Delhi, India         NaN                 Crossover   \n",
       "1         New Delhi, Delhi, India         NaN                 Crossover   \n",
       "2          Greater Bengaluru Area         NaN                    Uplers   \n",
       "3        Gurugram, Haryana, India         NaN             PVAR SERVICES   \n",
       "4  Mohali district, Punjab, India         NaN  Timeline Freight Brokers   \n",
       "\n",
       "  work_type              full_time_remote  \\\n",
       "0    Remote         Full-time · Associate   \n",
       "1    Remote         Full-time · Associate   \n",
       "2    Remote  Full-time · Mid-Senior level   \n",
       "3   On-site                     Full-time   \n",
       "4   On-site                     Full-time   \n",
       "\n",
       "                                        no_of_employ no_of_application  \\\n",
       "0  1,001-5,000 employees · IT Services and IT Con...               200   \n",
       "1  1,001-5,000 employees · IT Services and IT Con...               184   \n",
       "2  1,001-5,000 employees · IT Services and IT Con...               200   \n",
       "3                                     1-10 employees               200   \n",
       "4                                     1-10 employees                 8   \n",
       "\n",
       "  posted_day_ago             alumni           Hiring_person  \\\n",
       "0        8 hours  12 company alumni                     NaN   \n",
       "1        8 hours  12 company alumni                     NaN   \n",
       "2        9 hours   3 company alumni            Shahid Ahmad   \n",
       "3        7 hours                NaN           Vartika Singh   \n",
       "4     26 minutes   1 company alumni  Manisha (Gisele Smith)   \n",
       "\n",
       "    linkedin_followers                                 hiring_person_link  \\\n",
       "0  5,395,547 followers                                                NaN   \n",
       "1  5,395,547 followers                                                NaN   \n",
       "2                  NaN  https://www.linkedin.com/in/shahid-ahmad-a2613...   \n",
       "3      2,094 followers         https://www.linkedin.com/in/vartika-singh-   \n",
       "4                  NaN     https://www.linkedin.com/in/manisharathore0029   \n",
       "\n",
       "                                         job_details  Column1  \n",
       "0  About the job Crossover is the world's #1 sour...      NaN  \n",
       "1  About the job Crossover is the world's #1 sour...      NaN  \n",
       "2  About the job Profile: ML EngineersExperience:...      NaN  \n",
       "3  About the job Designation: Data AnalystLocatio...      NaN  \n",
       "4  About the job The ideal candidate will use the...      NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c82b892",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_principales = [\n",
    "    \"Data Analyst\", \"Software Engineer\", \"Project Manager\", \"Product Manager\",\n",
    "    \"Account Manager\", \"Sales Representative\", \"Data Scientist\", \"Business Analyst\",\n",
    "    \"Marketing Manager\", \"Graphic Designer\", \"UX/UI Designer\", \"Operations Manager\",\n",
    "    \"Financial Analyst\", \"Human Resources Manager\", \"Administrative Assistant\",\n",
    "    \"Customer Service Representative\", \"Web Developer\", \"Network Engineer\",\n",
    "    \"Systems Analyst\", \"Consultant\", \"Quality Assurance Engineer\", \"SEO Specialist\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c21a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_posicion(posicion):\n",
    "    # Check if the input is a string\n",
    "    if isinstance(posicion, str):\n",
    "        categoria, score = process.extractOne(posicion, categorias_principales)\n",
    "        if score > 85:\n",
    "            return categoria\n",
    "        else:\n",
    "            return \"Otro\"\n",
    "    else:\n",
    "        # Return 'Otro' or a specific category for missing/invalid data\n",
    "        return \"No especificado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3827b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categoria'] = df['job'].apply(categorizar_posicion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cd46a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_ID</th>\n",
       "      <th>job</th>\n",
       "      <th>location</th>\n",
       "      <th>company_id</th>\n",
       "      <th>company_name</th>\n",
       "      <th>work_type</th>\n",
       "      <th>full_time_remote</th>\n",
       "      <th>no_of_employ</th>\n",
       "      <th>no_of_application</th>\n",
       "      <th>posted_day_ago</th>\n",
       "      <th>alumni</th>\n",
       "      <th>Hiring_person</th>\n",
       "      <th>linkedin_followers</th>\n",
       "      <th>hiring_person_link</th>\n",
       "      <th>job_details</th>\n",
       "      <th>Column1</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3471657636</td>\n",
       "      <td>Data Analyst, Trilogy (Remote) - $60,000/year USD</td>\n",
       "      <td>Delhi, Delhi, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crossover</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>200</td>\n",
       "      <td>8 hours</td>\n",
       "      <td>12 company alumni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,395,547 followers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job Crossover is the world's #1 sour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3471669068</td>\n",
       "      <td>Data Analyst, Trilogy (Remote) - $60,000/year USD</td>\n",
       "      <td>New Delhi, Delhi, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crossover</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Associate</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>184</td>\n",
       "      <td>8 hours</td>\n",
       "      <td>12 company alumni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,395,547 followers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job Crossover is the world's #1 sour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3474349934</td>\n",
       "      <td>Data Analyst - WFH</td>\n",
       "      <td>Greater Bengaluru Area</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uplers</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full-time · Mid-Senior level</td>\n",
       "      <td>1,001-5,000 employees · IT Services and IT Con...</td>\n",
       "      <td>200</td>\n",
       "      <td>9 hours</td>\n",
       "      <td>3 company alumni</td>\n",
       "      <td>Shahid Ahmad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/in/shahid-ahmad-a2613...</td>\n",
       "      <td>About the job Profile: ML EngineersExperience:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3472816027</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Gurugram, Haryana, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PVAR SERVICES</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1-10 employees</td>\n",
       "      <td>200</td>\n",
       "      <td>7 hours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vartika Singh</td>\n",
       "      <td>2,094 followers</td>\n",
       "      <td>https://www.linkedin.com/in/vartika-singh-</td>\n",
       "      <td>About the job Designation: Data AnalystLocatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3473311511</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Mohali district, Punjab, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Timeline Freight Brokers</td>\n",
       "      <td>On-site</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>1-10 employees</td>\n",
       "      <td>8</td>\n",
       "      <td>26 minutes</td>\n",
       "      <td>1 company alumni</td>\n",
       "      <td>Manisha (Gisele Smith)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/in/manisharathore0029</td>\n",
       "      <td>About the job The ideal candidate will use the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job_ID                                                job  \\\n",
       "0  3471657636  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
       "1  3471669068  Data Analyst, Trilogy (Remote) - $60,000/year USD   \n",
       "2  3474349934                                 Data Analyst - WFH   \n",
       "3  3472816027                                       Data Analyst   \n",
       "4  3473311511                                       Data Analyst   \n",
       "\n",
       "                         location  company_id              company_name  \\\n",
       "0             Delhi, Delhi, India         NaN                 Crossover   \n",
       "1         New Delhi, Delhi, India         NaN                 Crossover   \n",
       "2          Greater Bengaluru Area         NaN                    Uplers   \n",
       "3        Gurugram, Haryana, India         NaN             PVAR SERVICES   \n",
       "4  Mohali district, Punjab, India         NaN  Timeline Freight Brokers   \n",
       "\n",
       "  work_type              full_time_remote  \\\n",
       "0    Remote         Full-time · Associate   \n",
       "1    Remote         Full-time · Associate   \n",
       "2    Remote  Full-time · Mid-Senior level   \n",
       "3   On-site                     Full-time   \n",
       "4   On-site                     Full-time   \n",
       "\n",
       "                                        no_of_employ no_of_application  \\\n",
       "0  1,001-5,000 employees · IT Services and IT Con...               200   \n",
       "1  1,001-5,000 employees · IT Services and IT Con...               184   \n",
       "2  1,001-5,000 employees · IT Services and IT Con...               200   \n",
       "3                                     1-10 employees               200   \n",
       "4                                     1-10 employees                 8   \n",
       "\n",
       "  posted_day_ago             alumni           Hiring_person  \\\n",
       "0        8 hours  12 company alumni                     NaN   \n",
       "1        8 hours  12 company alumni                     NaN   \n",
       "2        9 hours   3 company alumni            Shahid Ahmad   \n",
       "3        7 hours                NaN           Vartika Singh   \n",
       "4     26 minutes   1 company alumni  Manisha (Gisele Smith)   \n",
       "\n",
       "    linkedin_followers                                 hiring_person_link  \\\n",
       "0  5,395,547 followers                                                NaN   \n",
       "1  5,395,547 followers                                                NaN   \n",
       "2                  NaN  https://www.linkedin.com/in/shahid-ahmad-a2613...   \n",
       "3      2,094 followers         https://www.linkedin.com/in/vartika-singh-   \n",
       "4                  NaN     https://www.linkedin.com/in/manisharathore0029   \n",
       "\n",
       "                                         job_details  Column1     categoria  \n",
       "0  About the job Crossover is the world's #1 sour...      NaN  Data Analyst  \n",
       "1  About the job Crossover is the world's #1 sour...      NaN  Data Analyst  \n",
       "2  About the job Profile: ML EngineersExperience:...      NaN  Data Analyst  \n",
       "3  About the job Designation: Data AnalystLocatio...      NaN  Data Analyst  \n",
       "4  About the job The ideal candidate will use the...      NaN  Data Analyst  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "265e7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('tu_archivo_categorizado.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9611f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analyst' 'Otro' 'Quality Assurance Engineer' 'Web Developer'\n",
      " 'Business Analyst' 'Network Engineer' 'Software Engineer'\n",
      " 'Marketing Manager' 'Data Scientist' 'Project Manager' 'Consultant'\n",
      " 'Administrative Assistant' 'No especificado' 'SEO Specialist'\n",
      " 'Systems Analyst' 'Product Manager' 'Human Resources Manager'\n",
      " 'Financial Analyst' 'Sales Representative' 'Operations Manager'\n",
      " 'Account Manager' 'UX/UI Designer' 'Customer Service Representative'\n",
      " 'Graphic Designer']\n"
     ]
    }
   ],
   "source": [
    "print(df['categoria'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c0241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
